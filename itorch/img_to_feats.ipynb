{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package.path = '../?.lua;'..package.path\n",
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'image'\n",
    "\n",
    "require 'densecap.DenseCapModel'\n",
    "utils = require 'densecap.utils'\n",
    "box_utils = require 'densecap.box_utils'\n",
    "vis_utils = require 'densecap.vis_utils'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- load model\n",
    "dtype, use_cudnn = utils.setup_gpus(0, 1)\n",
    "print(dtype, use_cudnn)\n",
    "checkpoint = '../data/models/densecap/densecap-pretrained-vgg16.t7'\n",
    "model = torch.load(checkpoint).model\n",
    "model:convert(dtype, use_cudnn)\n",
    "model:evaluate()\n",
    "-- model test option\n",
    "model:setTestArgs{rpn_nms_thresh = 0.7, \n",
    "                  final_nms_thresh = 0.3,\n",
    "                  num_proposals = 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function view_box(box)\n",
    "    x1 = torch.floor(box[1]-box[3]/2+1)\n",
    "    y1 = torch.floor(box[2]-box[4]/2+1)\n",
    "    x2 = x1 + box[3] - 1\n",
    "    y2 = y1 + box[4] - 1\n",
    "    itorch.image(img[{ {}, {y1, y2}, {x1, x2} }])\n",
    "end\n",
    "-- options\n",
    "image_size = 720\n",
    "img_path = '../imgs/elephant.jpg'\n",
    "box_width = 2\n",
    "-- read image and box\n",
    "img = image.load(img_path, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = image.scale(img, image_size):float()\n",
    "H, W = img:size(2), img:size(3)\n",
    "-- convert img\n",
    "img_caffe = img:view(1, 3, H, W)\n",
    "img_caffe = img_caffe:index(2, torch.LongTensor{3,2,1}):mul(255)\n",
    "vgg_mean = torch.FloatTensor{103.939, 116.779, 123.68}\n",
    "vgg_mean = vgg_mean:view(1, 3, 1, 1):expand(1, 3, H, W)\n",
    "img_caffe:add(-1, vgg_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = model:extractAllFeatures(img_caffe:type(dtype))\n",
    "boxes_scores, seqs, roi_codes, hidden_codes, captions = unpack(out)\n",
    "print(boxes_scores:size(),boxes_scores:type())\n",
    "print(roi_codes:size(), roi_codes:type())\n",
    "print(hidden_codes:size(), hidden_codes:type())\n",
    "print(seqs:size(), seqs:type())\n",
    "print(captions[1], captions[2], captions[3], captions[4], captions[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- forward_test\n",
    "boxes, scores, captions = model:forward_test(img_caffe:type(dtype))\n",
    "print(boxes:size(), boxes:type())\n",
    "print(captions[1], captions[2], captions[3], captions[4], captions[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
